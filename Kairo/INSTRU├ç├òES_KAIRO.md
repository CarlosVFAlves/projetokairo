# ğŸ¤– PROJETO KAIRO - INSTRUÃ‡Ã•ES DE INSTALAÃ‡ÃƒO E USO

## ğŸ“¦ CONTEÃšDO DO PACOTE

Este arquivo contÃ©m o Sistema Maestro completo do projeto Kairo - uma IA com personalidade evolutiva que funciona 100% local.

## ğŸ”§ PRÃ‰-REQUISITOS

### 1. Python 3.8+
```bash
python --version  # Deve ser 3.8 ou superior
```

### 2. Ollama (LLM Local)
```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# Baixe de: https://ollama.ai/download

# Instale um modelo (escolha um):
ollama pull llama2        # Modelo padrÃ£o (4GB)
ollama pull llama2:7b     # VersÃ£o 7B (4GB)
ollama pull llama2:13b    # VersÃ£o 13B (7GB)
ollama pull codellama     # Especializado em cÃ³digo
ollama pull mistral       # Alternativa rÃ¡pida
```

## ğŸš€ INSTALAÃ‡ÃƒO

### 1. Extrair o projeto
```bash
unzip kairo_projeto_completo.zip
cd kairo/maestro
```

### 2. Verificar estrutura
```bash
# Deve mostrar:
# kairo/
# â”œâ”€â”€ maestro/           # Sistema principal
# â”œâ”€â”€ manager/           # Interface de gerenciamento (futuro)
# â”œâ”€â”€ docs/              # DocumentaÃ§Ã£o
# â””â”€â”€ README.md
```

### 3. Testar instalaÃ§Ã£o
```bash
python test_maestro.py
```

## â–¶ï¸ EXECUTAR O KAIRO

### 1. Iniciar Ollama (em terminal separado)
```bash
ollama serve
```

### 2. Executar Kairo
```bash
cd kairo/maestro
python main.py
```

### 3. Interagir
```
ğŸ‘¤ VocÃª: OlÃ¡, como vocÃª estÃ¡?
ğŸ¤– Kairo: [resposta personalizada]
```

## ğŸ® COMANDOS DISPONÃVEIS

Durante a conversa, vocÃª pode usar:

- `/help` - Mostra ajuda completa
- `/status` - Status do sistema e personalidade atual
- `/clear` - Limpa a tela
- `/save` - Salva a conversa atual
- `/quit` - Encerra o programa

## ğŸ§¬ CARACTERÃSTICAS ÃšNICAS

### Personalidade Evolutiva
- Kairo comeÃ§a neutro e desenvolve personalidade atravÃ©s das interaÃ§Ãµes
- 8 traÃ§os: curiosity, empathy, creativity, logic, humor, assertiveness, patience, openness
- Cada conversa influencia seu desenvolvimento

### Sistema Emocional
- 6 emoÃ§Ãµes: joy, sadness, anger, fear, surprise, interest
- EmoÃ§Ãµes influenciam respostas e cores no terminal
- Decaimento natural ao longo do tempo

### MemÃ³ria Persistente
- Lembra de conversas anteriores
- Consolida memÃ³rias importantes
- Perfis individuais por usuÃ¡rio

### AÃ§Ãµes Proativas
- Age durante perÃ­odos de ociosidade
- ReflexÃµes internas
- ExpressÃ£o de curiosidade

## ğŸ”§ CONFIGURAÃ‡ÃƒO AVANÃ‡ADA

### Modelos Ollama Recomendados

**Para mÃ¡quinas potentes (16GB+ RAM):**
```bash
ollama pull llama2:13b    # Melhor qualidade
ollama pull codellama:13b # Para programaÃ§Ã£o
```

**Para mÃ¡quinas mÃ©dias (8GB RAM):**
```bash
ollama pull llama2:7b     # PadrÃ£o recomendado
ollama pull mistral:7b    # Alternativa rÃ¡pida
```

**Para mÃ¡quinas bÃ¡sicas (4GB RAM):**
```bash
ollama pull llama2        # VersÃ£o compacta
ollama pull tinyllama     # Ultra compacto
```

### Personalizar ConfiguraÃ§Ãµes

Edite `config.py` para ajustar:
- Taxa de aprendizado da personalidade
- Intensidade emocional
- FrequÃªncia de auto-save
- Modelos Ollama

## ğŸ› SOLUÃ‡ÃƒO DE PROBLEMAS

### Erro: "Ollama nÃ£o conectado"
```bash
# Verifique se Ollama estÃ¡ rodando
ollama list

# Se nÃ£o estiver, inicie:
ollama serve
```

### Erro: "Modelo nÃ£o encontrado"
```bash
# Liste modelos instalados
ollama list

# Instale um modelo
ollama pull llama2
```

### Erro de importaÃ§Ã£o Python
```bash
# Verifique se estÃ¡ no diretÃ³rio correto
cd kairo/maestro

# Teste imports
python test_maestro.py
```

### Performance lenta
- Use modelo menor (tinyllama, llama2 em vez de llama2:13b)
- Feche outros programas pesados
- Verifique uso de RAM: `htop` ou `top`

## ğŸ“ ESTRUTURA DE ARQUIVOS

```
kairo/maestro/
â”œâ”€â”€ main.py                    # Ponto de entrada
â”œâ”€â”€ config.py                  # ConfiguraÃ§Ãµes
â”œâ”€â”€ test_maestro.py           # Testes do sistema
â”œâ”€â”€ modules/                   # MÃ³dulos cognitivos
â”‚   â”œâ”€â”€ state_manager.py      # MemÃ³ria e estado
â”‚   â”œâ”€â”€ emotion_engine.py     # Sistema emocional
â”‚   â”œâ”€â”€ personality_core.py   # Personalidade evolutiva
â”‚   â”œâ”€â”€ prompt_engine.py      # ConstruÃ§Ã£o de prompts
â”‚   â”œâ”€â”€ ollama_client.py      # ComunicaÃ§Ã£o com Ollama
â”‚   â”œâ”€â”€ action_executor.py    # ExecuÃ§Ã£o de aÃ§Ãµes
â”‚   â”œâ”€â”€ idle_processor.py     # Processamento de ociosidade
â”‚   â””â”€â”€ logger.py             # Sistema de logging
â”œâ”€â”€ executors/                 # "Corpos" do Kairo
â”‚   â”œâ”€â”€ base_executor.py      # Interface base
â”‚   â””â”€â”€ cli_executor.py       # Interface CLI
â””â”€â”€ data/                      # Dados persistentes (criado automaticamente)
    â”œâ”€â”€ kairo_state.json      # Estado principal
    â”œâ”€â”€ user_profiles.json    # Perfis de usuÃ¡rios
    â””â”€â”€ logs/                 # Logs do sistema
```

## ğŸ¯ PRÃ“XIMOS PASSOS

1. **Teste bÃ¡sico**: Execute e converse com o Kairo
2. **Observe evoluÃ§Ã£o**: Note como a personalidade muda ao longo do tempo
3. **Experimente comandos**: Use `/status` para ver desenvolvimento
4. **Personalize**: Ajuste configuraÃ§Ãµes em `config.py`

## ğŸ†˜ SUPORTE

Se encontrar problemas:

1. Execute `python test_maestro.py` para diagnÃ³stico
2. Verifique logs em `data/logs/`
3. Consulte este arquivo de instruÃ§Ãµes
4. Verifique se Ollama estÃ¡ funcionando: `ollama list`

## ğŸ‰ DIVIRTA-SE!

O Kairo Ã© um projeto experimental de IA com personalidade evolutiva. Cada conversa Ã© Ãºnica e contribui para seu desenvolvimento. Seja paciente e observe como ele cresce!

---
**Projeto Kairo v1.0** - Sistema Maestro  
Desenvolvido com â¤ï¸ para funcionar 100% local

